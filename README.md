# DeepLearning
Some deep learning school projects :

- Grad-CAM (Gradient-weighted Class Activation Mapping) is a technique used to visualize and interpret the decisions made by convolutional neural networks (CNNs). It highlights the regions of an input image that are most relevant to the model's prediction. Grad-CAM works by computing the gradient of the target class score with respect to the feature maps of a convolutional layer. These gradients are then used to generate a heatmap that shows which parts of the image have the most influence on the final decision. This helps in understanding and explaining the inner workings of CNNs, making them more transparent and interpretable.

![image](https://github.com/MOMOJordan/DeepLearning/assets/86100448/c1ff92af-80a9-4d39-9a0f-7d45d4bcdd06)
![image](https://github.com/MOMOJordan/DeepLearning/assets/86100448/44307195-1877-48fd-9f17-d997006011d7)

-  VAE (Variational Autoencoder)  is a type of generative model that learns to encode input data into a compressed latent space and then decode it back to the original data space. It consists of two main components: an encoder, which maps input data to a probabilistic latent representation, and a decoder, which reconstructs the data from this latent space. Unlike traditional autoencoders, VAEs introduce a probabilistic approach by encoding data as a distribution rather than a fixed point, allowing for the generation of new, similar data by sampling from the latent space. This makes VAEs powerful tools for tasks such as data generation, anomaly detection, and representation learning.

![image](https://github.com/MOMOJordan/DeepLearning/assets/86100448/4e97323b-76c6-4c86-b0b3-4742a95893ee)
![image](https://github.com/MOMOJordan/DeepLearning/assets/86100448/78069c0b-6a25-4a07-a5d4-e0e00716e1af)

- Physics-Informed Neural Networks (PINNs) using Koopman operator. The Koopman operator is a theoretical framework used in dynamical systems to analyze the evolution of observables (functions of the state space) rather than the state variables themselves. It provides a linear perspective on nonlinear dynamical systems by transforming the original nonlinear system into an infinite-dimensional linear system. The Koopman operator theory allows for the application of linear techniques to study complex, nonlinear dynamics.

 ![image](https://github.com/MOMOJordan/DeepLearning/assets/86100448/de331d22-8fc0-4b9e-a001-6221d328a6cb)
 
 ![image](https://github.com/MOMOJordan/DeepLearning/assets/86100448/f7b98869-5e0a-47a1-92d3-10b7bb3c35d6)
 
 ![image](https://github.com/MOMOJordan/DeepLearning/assets/86100448/4aca575f-69c4-4282-9ba0-43a956f1d1c0)

- Transfer Learning
Transfer learning is a machine learning technique where a model developed for a particular task is reused as the starting point for a model on a second, related task. This approach leverages the knowledge gained from the initial task to improve learning efficiency and performance on the new task, particularly when data is limited. 

- Data Augmentation
Data augmentation is a technique used to increase the diversity and quantity of training data without actually collecting new data. This is achieved by applying various transformations to existing data, such as rotations, translations, scaling, flipping, and adding noise. These transformations help the model generalize better by exposing it to a wider variety of scenarios.

![image](https://github.com/MOMOJordan/DeepLearning/assets/86100448/74b4a0e4-2b51-4f29-b476-97874378a926)
![image](https://github.com/MOMOJordan/DeepLearning/assets/86100448/398040ae-2002-4164-875c-999525f0d891)


